{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T12:00:14.511568Z",
     "start_time": "2018-10-25T12:00:14.508586Z"
    }
   },
   "outputs": [],
   "source": [
    "from singa import tensor\n",
    "from singa.tensor import Tensor\n",
    "from singa import autograd\n",
    "from singa import optimizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T12:00:15.531097Z",
     "start_time": "2018-10-25T12:00:15.500555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_shape: (400, 2)\n",
      "train_label_shape: (400, 2)\n"
     ]
    }
   ],
   "source": [
    "autograd.training = True\n",
    "\n",
    "# prepare training data in numpy array\n",
    "\n",
    "# generate the boundary\n",
    "f = lambda x: (5 * x + 1)\n",
    "bd_x = np.linspace(-1., 1, 200)\n",
    "bd_y = f(bd_x)\n",
    "# generate the training data\n",
    "x = np.random.uniform(-1, 1, 400)\n",
    "y = f(x) + 2 * np.random.randn(len(x))\n",
    "# convert training data to 2d space\n",
    "label = np.asarray([5 * a + 1 > b for (a, b) in zip(x, y)])\n",
    "data = np.array([[a, b] for (a, b) in zip(x, y)], dtype=np.float32)\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    '''\n",
    "    Converts a class vector (integers) to binary class matrix.\n",
    "    Args\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    Return\n",
    "        A binary matrix representation of the input.\n",
    "    '''\n",
    "    y = np.array(y, dtype='int')\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "label = to_categorical(label, 2).astype(np.float32)\n",
    "print('train_data_shape:', data.shape)\n",
    "print('train_label_shape:', label.shape)\n",
    "\n",
    "inputs = Tensor(data=data)\n",
    "target = Tensor(data=label)\n",
    "\n",
    "w0 = Tensor(shape=(2, 2), requires_grad=True, stores_grad=True)\n",
    "w0.gaussian(0.0, 0.1)\n",
    "b0 = Tensor(shape=(1, 2), requires_grad=True, stores_grad=True)\n",
    "b0.set_value(0.0)\n",
    "\n",
    "w1 = Tensor(shape=(2, 2), requires_grad=True, stores_grad=True)\n",
    "w1.gaussian(0.0, 0.1)\n",
    "b1 = Tensor(shape=(1, 2), requires_grad=True, stores_grad=True)\n",
    "b1.set_value(0.0)\n",
    "\n",
    "w2 = Tensor(shape=(2, 2), requires_grad=True, stores_grad=True)\n",
    "w2.gaussian(0.0, 0.1)\n",
    "b2 = Tensor(shape=(1, 2), requires_grad=True, stores_grad=True)\n",
    "b2.set_value(0.0)\n",
    "\n",
    "sgd = optimizer.SGD(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T10:24:03.843329Z",
     "start_time": "2018-10-24T10:24:03.834293Z"
    }
   },
   "outputs": [],
   "source": [
    "#sgd.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T12:19:38.190183Z",
     "start_time": "2018-10-25T12:19:37.513575Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss =  0.6918451\n",
      "training loss =  0.6151072\n",
      "training loss =  0.58906007\n",
      "training loss =  0.572035\n",
      "training loss =  0.53840005\n",
      "training loss =  0.42323416\n",
      "training loss =  0.31211025\n",
      "training loss =  0.23464933\n",
      "training loss =  0.18611358\n",
      "training loss =  0.1552738\n",
      "training loss =  0.13001356\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "for i in range(1001):\n",
    "    x = autograd.matmul(inputs, w0)\n",
    "    x = autograd.add_bias(x, b0)\n",
    "    x = autograd.relu(x)\n",
    "    x = autograd.matmul(x, w1)\n",
    "    x = autograd.add_bias(x, b1)\n",
    "    x = autograd.soft_max(x)\n",
    "    loss = autograd.cross_entropy(x, target)\n",
    "    #print(autograd.backward(loss))\n",
    "    for p, gp in autograd.backward(loss).items():\n",
    "        #print(p.shape)\n",
    "        #print(gp.shape)\n",
    "        gp.reshape(p.shape)\n",
    "        #print()\n",
    "        #gp = gp.reshape(p.shape)\n",
    "        #print(gp.shape)\n",
    "        sgd.apply(0, gp, p, '')\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print('training loss = ', tensor.to_numpy(loss)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    x = autograd.matmul(inputs, w0)\n",
    "    x = autograd.add_bias(x, b0)\n",
    "    #x = autograd.relu(x)\n",
    "    x2 = autograd.matmul(x, w2)\n",
    "    x2 = autograd.add_bias(x2, b2)\n",
    "    x1 = autograd.matmul(x, w1)\n",
    "    x1 = autograd.add_bias(x1, b1)\n",
    "    x3 = autograd.add(x1,x2)\n",
    "    x3 = autograd.softmax(x3)\n",
    "    loss = autograd.cross_entropy(x3, target)\n",
    "    for p, gp in autograd.backward(loss):\n",
    "        #gp.reshape(p.shape)\n",
    "        pass\n",
    "        #sgd.apply(0, gp, p, '')\n",
    "    print('training loss = ', tensor.to_numpy(loss)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
