{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T02:09:34.242521Z",
     "start_time": "2018-10-19T02:09:34.233996Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T02:09:37.226753Z",
     "start_time": "2018-10-19T02:09:34.782451Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_input = Variable(torch.randn(10, 3, 224, 224))\n",
    "model = torchvision.models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T02:10:08.312623Z",
     "start_time": "2018-10-19T02:09:37.229323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224)\n",
      "      %1 : Float(64, 3, 3, 3)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(128, 64, 3, 3)\n",
      "      %4 : Float(128)\n",
      "      %5 : Float(256, 128, 3, 3)\n",
      "      %6 : Float(256)\n",
      "      %7 : Float(256, 256, 3, 3)\n",
      "      %8 : Float(256)\n",
      "      %9 : Float(512, 256, 3, 3)\n",
      "      %10 : Float(512)\n",
      "      %11 : Float(512, 512, 3, 3)\n",
      "      %12 : Float(512)\n",
      "      %13 : Float(512, 512, 3, 3)\n",
      "      %14 : Float(512)\n",
      "      %15 : Float(512, 512, 3, 3)\n",
      "      %16 : Float(512)\n",
      "      %17 : Float(4096, 25088)\n",
      "      %18 : Float(4096)\n",
      "      %19 : Float(4096, 4096)\n",
      "      %20 : Float(4096)\n",
      "      %21 : Float(1000, 4096)\n",
      "      %22 : Float(1000)) {\n",
      "  %23 : Float(10, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%0, %1, %2), scope: VGG/Sequential[features]/Conv2d[0]\n",
      "  %24 : Float(10, 64, 224, 224) = onnx::Relu(%23), scope: VGG/Sequential[features]/ReLU[1]\n",
      "  %25 : Float(10, 64, 112, 112) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%24), scope: VGG/Sequential[features]/MaxPool2d[2]\n",
      "  %26 : Float(10, 128, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%25, %3, %4), scope: VGG/Sequential[features]/Conv2d[3]\n",
      "  %27 : Float(10, 128, 112, 112) = onnx::Relu(%26), scope: VGG/Sequential[features]/ReLU[4]\n",
      "  %28 : Float(10, 128, 56, 56) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%27), scope: VGG/Sequential[features]/MaxPool2d[5]\n",
      "  %29 : Float(10, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%28, %5, %6), scope: VGG/Sequential[features]/Conv2d[6]\n",
      "  %30 : Float(10, 256, 56, 56) = onnx::Relu(%29), scope: VGG/Sequential[features]/ReLU[7]\n",
      "  %31 : Float(10, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%30, %7, %8), scope: VGG/Sequential[features]/Conv2d[8]\n",
      "  %32 : Float(10, 256, 56, 56) = onnx::Relu(%31), scope: VGG/Sequential[features]/ReLU[9]\n",
      "  %33 : Float(10, 256, 28, 28) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%32), scope: VGG/Sequential[features]/MaxPool2d[10]\n",
      "  %34 : Float(10, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%33, %9, %10), scope: VGG/Sequential[features]/Conv2d[11]\n",
      "  %35 : Float(10, 512, 28, 28) = onnx::Relu(%34), scope: VGG/Sequential[features]/ReLU[12]\n",
      "  %36 : Float(10, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%35, %11, %12), scope: VGG/Sequential[features]/Conv2d[13]\n",
      "  %37 : Float(10, 512, 28, 28) = onnx::Relu(%36), scope: VGG/Sequential[features]/ReLU[14]\n",
      "  %38 : Float(10, 512, 14, 14) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%37), scope: VGG/Sequential[features]/MaxPool2d[15]\n",
      "  %39 : Float(10, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%38, %13, %14), scope: VGG/Sequential[features]/Conv2d[16]\n",
      "  %40 : Float(10, 512, 14, 14) = onnx::Relu(%39), scope: VGG/Sequential[features]/ReLU[17]\n",
      "  %41 : Float(10, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%40, %15, %16), scope: VGG/Sequential[features]/Conv2d[18]\n",
      "  %42 : Float(10, 512, 14, 14) = onnx::Relu(%41), scope: VGG/Sequential[features]/ReLU[19]\n",
      "  %43 : Float(10, 512, 7, 7) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%42), scope: VGG/Sequential[features]/MaxPool2d[20]\n",
      "  %44 : Long() = onnx::Constant[value={0}]()\n",
      "  %45 : Dynamic = onnx::Shape(%43), scope: VGG\n",
      "  %46 : Long() = onnx::Gather[axis=0](%45, %44), scope: VGG\n",
      "  %47 : Long() = onnx::Constant[value={-1}]()\n",
      "  %48 : Dynamic = onnx::Unsqueeze[axes=[0]](%46), scope: VGG\n",
      "  %49 : Dynamic = onnx::Unsqueeze[axes=[0]](%47), scope: VGG\n",
      "  %50 : int[] = onnx::Concat[axis=0](%48, %49), scope: VGG\n",
      "  %51 : Float(10, 25088) = onnx::Reshape(%43, %50), scope: VGG\n",
      "  %52 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%51, %17, %18)\n",
      "  %53 : Float(10, 4096) = onnx::Relu(%52), scope: VGG/Sequential[classifier]/ReLU[1]\n",
      "  %54 : Float(10, 4096), %55 : Dynamic = onnx::Dropout[ratio=0.5](%53), scope: VGG/Sequential[classifier]/Dropout[2]\n",
      "  %56 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%54, %19, %20)\n",
      "  %57 : Float(10, 4096) = onnx::Relu(%56), scope: VGG/Sequential[classifier]/ReLU[4]\n",
      "  %58 : Float(10, 4096), %59 : Dynamic = onnx::Dropout[ratio=0.5](%57), scope: VGG/Sequential[classifier]/Dropout[5]\n",
      "  %60 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, transB=1](%58, %21, %22)\n",
      "  return (%60);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Providing input and output names sets the display names for values\n",
    "# within the model's graph. Setting these does not change the semantics\n",
    "# of the graph; it is only for readability.\n",
    "#\n",
    "# The inputs to the network consist of the flat list of inputs (i.e.\n",
    "# the values you would pass to the forward() method) followed by the\n",
    "# flat list of parameters. You can partially specify names, i.e. provide\n",
    "# a list here shorter than the number of inputs to the model, and we will\n",
    "# only set that subset of names, starting from the beginning.\n",
    "#input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "#output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"vgg.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:51:15.085494Z",
     "start_time": "2018-10-21T08:51:12.469305Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"vgg.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "#onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:35:44.822909Z",
     "start_time": "2018-10-21T09:35:44.809333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"0\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 10\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 224\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 224\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"1\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 64\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"2\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 64\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"3\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 128\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 64\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"4\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 128\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"5\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 128\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"6\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"7\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"8\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"9\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 256\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"10\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"11\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"12\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"13\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"14\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"15\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"16\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 512\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"17\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 25088\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"18\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"19\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"20\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"21\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1000\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 4096\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"22\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: FLOAT\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1000\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:51:27.234589Z",
     "start_time": "2018-10-21T08:51:15.991915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.589579   -0.05874371 -0.10375194 ... -1.4284072  -0.0739091\n",
      "   2.4973583 ]\n",
      " [-1.8856354   0.24618089  0.42049494 ... -1.209184   -0.7466364\n",
      "   3.5512092 ]\n",
      " [-2.155446   -0.05488757  0.38757893 ... -1.112158   -0.43493274\n",
      "   2.7320828 ]\n",
      " ...\n",
      " [-2.3419056  -0.1237722  -0.23530596 ... -1.2911285  -0.4330385\n",
      "   2.886316  ]\n",
      " [-1.9893287   0.33303982  0.11155938 ... -0.96714675 -0.35925993\n",
      "   3.0011141 ]\n",
      " [-2.0039675   0.21027038  0.39200854 ... -1.1921556  -0.17904913\n",
      "   2.7132797 ]]\n"
     ]
    }
   ],
   "source": [
    "import caffe2.python.onnx.backend as backend\n",
    "import numpy as np\n",
    "\n",
    "rep = backend.prepare(model, device=\"CPU\") # or \"CPU\"\n",
    "# For the Caffe2 backend:\n",
    "#     rep.predict_net is the Caffe2 protobuf for the network\n",
    "#     rep.workspace is the Caffe2 workspace for the network\n",
    "#       (see the class caffe2.python.onnx.backend.Workspace)\n",
    "outputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32))\n",
    "# To run networks with more than one input, pass a tuple\n",
    "# rather than a single numpy ndarray.\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T06:44:45.145500Z",
     "start_time": "2018-10-18T06:44:45.120778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Numpy array:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "TensorProto:\n",
      "dims: 2\n",
      "dims: 3\n",
      "data_type: DOUBLE\n",
      "raw_data: \"\\000\\000\\000\\000\\000\\000\\360?\\000\\000\\000\\000\\000\\000\\000@\\000\\000\\000\\000\\000\\000\\010@\\000\\000\\000\\000\\000\\000\\020@\\000\\000\\000\\000\\000\\000\\024@\\000\\000\\000\\000\\000\\000\\030@\"\n",
      "\n",
      "After round trip, Numpy array:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "3.5\n",
      "\n",
      "tensor.SerializeToString()\n",
      "b'\\x08\\x02\\x08\\x03\\x10\\x0bJ0\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@\\x00\\x00\\x00\\x00\\x00\\x00\\x14@\\x00\\x00\\x00\\x00\\x00\\x00\\x18@'\n",
      "b'\\x80\\x03]q\\x00(]q\\x01(K\\x01K\\x02K\\x03e]q\\x02(K\\x04K\\x05K\\x06ee.'\n",
      "end\n",
      "After saving and loading, new TensorProto:\n",
      "dims: 2\n",
      "dims: 3\n",
      "data_type: DOUBLE\n",
      "raw_data: \"\\000\\000\\000\\000\\000\\000\\360?\\000\\000\\000\\000\\000\\000\\000@\\000\\000\\000\\000\\000\\000\\010@\\000\\000\\000\\000\\000\\000\\020@\\000\\000\\000\\000\\000\\000\\024@\\000\\000\\000\\000\\000\\000\\030@\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# Preprocessing: create a Numpy array\n",
    "numpy_array = numpy.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=float)\n",
    "print('Original Numpy array:\\n{}\\n'.format(numpy_array))\n",
    "\n",
    "# Convert the Numpy array to a TensorProto\n",
    "tensor = numpy_helper.from_array(numpy_array)\n",
    "print('TensorProto:\\n{}'.format(tensor))\n",
    "\n",
    "# Convert the TensorProto to a Numpy array\n",
    "new_array = numpy_helper.to_array(tensor)\n",
    "print('After round trip, Numpy array:\\n{}'.format(numpy_array))\n",
    "print(numpy_array.mean())\n",
    "print()\n",
    "\n",
    "# Save the TensorProto\n",
    "with open('tensor.pb', 'wb') as f:\n",
    "    f.write(tensor.SerializeToString())\n",
    "print('tensor.SerializeToString()')\n",
    "print(tensor.SerializeToString())\n",
    "print(pickle.dumps([[1., 2., 3.],[4., 5., 6.]]))\n",
    "print('end')\n",
    "\n",
    "# Load a TensorProto\n",
    "new_tensor = onnx.TensorProto()\n",
    "with open('tensor.pb', 'rb') as f:\n",
    "    new_tensor.ParseFromString(f.read())\n",
    "print('After saving and loading, new TensorProto:\\n{}'.format(new_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:58:21.855903Z",
     "start_time": "2018-10-20T12:58:21.565356Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import AttributeProto, TensorProto, GraphProto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:58:46.814505Z",
     "start_time": "2018-10-20T12:58:46.791080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onnx.onnx_ONNX_REL_1_3_ml_pb2.AttributeProto"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AttributeProto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:58:39.159088Z",
     "start_time": "2018-10-20T12:58:39.133744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ir_version in model: 3\n",
      "\n",
      "The producer_name in model: onnx-example\n",
      "\n",
      "The graph in model:\n",
      "node {\n",
      "  input: \"X\"\n",
      "  output: \"Y\"\n",
      "  op_type: \"Pad\"\n",
      "  attribute {\n",
      "    name: \"mode\"\n",
      "    s: \"constant\"\n",
      "    type: STRING\n",
      "  }\n",
      "  attribute {\n",
      "    name: \"pads\"\n",
      "    ints: 0\n",
      "    ints: 1\n",
      "    ints: 0\n",
      "    ints: 1\n",
      "    type: INTS\n",
      "  }\n",
      "  attribute {\n",
      "    name: \"value\"\n",
      "    f: 1.5\n",
      "    type: FLOAT\n",
      "  }\n",
      "}\n",
      "name: \"test-model\"\n",
      "input {\n",
      "  name: \"X\"\n",
      "  type {\n",
      "    tensor_type {\n",
      "      elem_type: FLOAT\n",
      "      shape {\n",
      "        dim {\n",
      "          dim_value: 1\n",
      "        }\n",
      "        dim {\n",
      "          dim_value: 2\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"Y\"\n",
      "  type {\n",
      "    tensor_type {\n",
      "      elem_type: FLOAT\n",
      "      shape {\n",
      "        dim {\n",
      "          dim_value: 1\n",
      "        }\n",
      "        dim {\n",
      "          dim_value: 4\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "The model is checked!\n"
     ]
    }
   ],
   "source": [
    "# The protobuf definition can be found here:\n",
    "# https://github.com/onnx/onnx/blob/master/onnx/onnx.proto\n",
    "\n",
    "\n",
    "# Create one input (ValueInfoProto)\n",
    "X = helper.make_tensor_value_info('X', TensorProto.FLOAT, [1, 2])\n",
    "\n",
    "# Create one output (ValueInfoProto)\n",
    "Y = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [1, 4])\n",
    "\n",
    "# Create a node (NodeProto)\n",
    "node_def = helper.make_node(\n",
    "    'Pad', # node name\n",
    "    ['X'], # inputs\n",
    "    ['Y'], # outputs\n",
    "    mode='constant', # Attributes\n",
    "    value=1.5,\n",
    "    pads=[0, 1, 0, 1],\n",
    ")\n",
    "\n",
    "# Create the graph (GraphProto)\n",
    "graph_def = helper.make_graph(\n",
    "    [node_def],\n",
    "    \"test-model\",\n",
    "    [X],\n",
    "    [Y],\n",
    ")\n",
    "\n",
    "# Create the model (ModelProto)\n",
    "model_def = helper.make_model(graph_def,\n",
    "                              producer_name='onnx-example')\n",
    "\n",
    "print('The ir_version in model: {}\\n'.format(model_def.ir_version))\n",
    "print('The producer_name in model: {}\\n'.format(model_def.producer_name))\n",
    "print('The graph in model:\\n{}'.format(model_def.graph))\n",
    "onnx.checker.check_model(model_def)\n",
    "print('The model is checked!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
